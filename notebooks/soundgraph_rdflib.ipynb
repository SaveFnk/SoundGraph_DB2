{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Spotify and YouTube dataset population\n",
    "\n",
    "This notebook outlines the steps to create an RDF dataset based on the SoundGraph ontology, from the data import to RDF triple export in Turtle format."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e953e7e47cdd4d59"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# required libraries\n",
    "from pathlib import Path\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "from rdflib.namespace import FOAF, XSD\n",
    "import ast\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:07.777852100Z",
     "start_time": "2023-12-10T18:18:07.412509100Z"
    }
   },
   "id": "ad98a76565745715"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load CSV files + preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1528fda7473d7cb9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# csv files path\n",
    "base_path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "\n",
    "dataset_path = base_path + '/data/Spotify_Youtube.csv'\n",
    "spotify_artist_path = base_path + '/data/Artists.csv'\n",
    "spotify_artist_info_path = base_path + '/data/Artist_info.csv'\n",
    "spotify_album_path = base_path + '/data/Album_info.csv'\n",
    "wikidata_artists_path = base_path + '/data/wikidata_artists.csv'\n",
    "wikidata_award_statements_path = base_path + '/data/wikidata_award_statements.csv'\n",
    "wikidata_awards_path = base_path + '/data/wikidata_awards_processed.csv'\n",
    "youtube_api_channels_path = base_path + '/data/youtubeapi_channels_complete.csv'\n",
    "# target path where to save the serializations\n",
    "rdf_path = base_path + '/rdf/' "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:07.778852Z",
     "start_time": "2023-12-10T18:18:07.769852900Z"
    }
   },
   "id": "4381a254bd1b04c6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20718 entries, 0 to 20717\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        20718 non-null  int64  \n",
      " 1   Artist            20718 non-null  object \n",
      " 2   Url_spotify       20718 non-null  object \n",
      " 3   Track             20718 non-null  object \n",
      " 4   Album             20718 non-null  object \n",
      " 5   Album_type        20718 non-null  object \n",
      " 6   Uri               20718 non-null  object \n",
      " 7   Danceability      20716 non-null  float64\n",
      " 8   Energy            20716 non-null  float64\n",
      " 9   Key               20716 non-null  float64\n",
      " 10  Loudness          20716 non-null  float64\n",
      " 11  Speechiness       20716 non-null  float64\n",
      " 12  Acousticness      20716 non-null  float64\n",
      " 13  Instrumentalness  20716 non-null  float64\n",
      " 14  Liveness          20716 non-null  float64\n",
      " 15  Valence           20716 non-null  float64\n",
      " 16  Tempo             20716 non-null  float64\n",
      " 17  Duration_ms       20716 non-null  float64\n",
      " 18  Url_youtube       20248 non-null  object \n",
      " 19  Title             20248 non-null  object \n",
      " 20  Channel           20248 non-null  object \n",
      " 21  Views             20248 non-null  float64\n",
      " 22  Likes             20177 non-null  float64\n",
      " 23  Comments          20149 non-null  float64\n",
      " 24  Description       19842 non-null  object \n",
      " 25  Licensed          20248 non-null  object \n",
      " 26  official_video    20248 non-null  object \n",
      " 27  Stream            20142 non-null  float64\n",
      "dtypes: float64(15), int64(1), object(12)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:08.775263400Z",
     "start_time": "2023-12-10T18:18:07.773852400Z"
    }
   },
   "id": "a36300b635ba08b2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2079 entries, 0 to 2078\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  2079 non-null   int64 \n",
      " 1   Artist      2079 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 32.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# TODO ma questo csv serve?\n",
    "spotify_artist = pd.read_csv(spotify_artist_path)\n",
    "spotify_artist.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:08.804263400Z",
     "start_time": "2023-12-10T18:18:08.774264500Z"
    }
   },
   "id": "74157c4f5452cfd5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2079 entries, 0 to 2078\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Artist      2079 non-null   object\n",
      " 1   Followers   2079 non-null   int64 \n",
      " 2   Genres      2079 non-null   object\n",
      " 3   Popularity  2079 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 65.1+ KB\n"
     ]
    }
   ],
   "source": [
    "spotify_artist_info = pd.read_csv(spotify_artist_info_path)\n",
    "spotify_artist_info.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:08.987263700Z",
     "start_time": "2023-12-10T18:18:08.795264100Z"
    }
   },
   "id": "ebe1d7fbe7063034"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2079 entries, 0 to 2078\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Artist         2079 non-null   object\n",
      " 1   Url_spotify    2079 non-null   object\n",
      " 2   artistLabel    2079 non-null   object\n",
      " 3   websiteLabel   2079 non-null   object\n",
      " 4   start          2079 non-null   object\n",
      " 5   end            2079 non-null   object\n",
      " 6   dissolved      2079 non-null   object\n",
      " 7   country_codes  2079 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 130.1+ KB\n"
     ]
    }
   ],
   "source": [
    "wikidata_artists = pd.read_csv(wikidata_artists_path)\n",
    "wikidata_artists.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:09.151270900Z",
     "start_time": "2023-12-10T18:18:08.982263600Z"
    }
   },
   "id": "5eda0d275249da10"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20718 entries, 0 to 20717\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Id                20718 non-null  object\n",
      " 1   Album             20641 non-null  object\n",
      " 2   Total_tracks      20718 non-null  int64 \n",
      " 3   Release_date      20718 non-null  object\n",
      " 4   Available_market  20718 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 809.4+ KB\n"
     ]
    }
   ],
   "source": [
    "spotify_album = pd.read_csv(spotify_album_path)\n",
    "spotify_album.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:09.657264600Z",
     "start_time": "2023-12-10T18:18:09.146264200Z"
    }
   },
   "id": "ffbecdb820942b89"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6715 entries, 0 to 6714\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   channelId           6715 non-null   object\n",
      " 1   title               6715 non-null   object\n",
      " 2   channelDescription  4241 non-null   object\n",
      " 3   viewCount           6715 non-null   object\n",
      " 4   subscriberCount     6715 non-null   object\n",
      " 5   videoCount          6715 non-null   object\n",
      " 6   error               6715 non-null   int64 \n",
      " 7   originalChannel     6715 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 419.8+ KB\n"
     ]
    }
   ],
   "source": [
    "youtube_api_channels = pd.read_csv(youtube_api_channels_path)\n",
    "youtube_api_channels.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:09.911264Z",
     "start_time": "2023-12-10T18:18:09.653266100Z"
    }
   },
   "id": "ad49c57f8805d84e"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 193 entries, 0 to 192\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   award_id        193 non-null    int64 \n",
      " 1   award_name      193 non-null    object\n",
      " 2   award_type      193 non-null    object\n",
      " 3   award_category  193 non-null    object\n",
      " 4   award_class     193 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 7.7+ KB\n"
     ]
    }
   ],
   "source": [
    "wikidata_awards = pd.read_csv(wikidata_awards_path)\n",
    "wikidata_awards.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:09.925263500Z",
     "start_time": "2023-12-10T18:18:09.909265600Z"
    }
   },
   "id": "70147b3d8307e1a0"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1001 entries, 0 to 1000\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   artist_spotify_id  1001 non-null   object\n",
      " 1   award_id           1001 non-null   int64 \n",
      " 2   award_year         1001 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 23.6+ KB\n"
     ]
    }
   ],
   "source": [
    "wikidata_awards_statements = pd.read_csv(wikidata_award_statements_path)\n",
    "wikidata_awards_statements.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:10.108291Z",
     "start_time": "2023-12-10T18:18:09.922263400Z"
    }
   },
   "id": "84029d3d90891f8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data cleaning\n",
    "We remove NaN values and make IDs explicit in the columns."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd50d826a08bca6e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Unnamed: 0          False\nArtist              False\nUrl_spotify         False\nTrack               False\nAlbum               False\nAlbum_type          False\nUri                 False\nDanceability         True\nEnergy               True\nKey                  True\nLoudness             True\nSpeechiness          True\nAcousticness         True\nInstrumentalness     True\nLiveness             True\nValence              True\nTempo                True\nDuration_ms          True\nUrl_youtube          True\nTitle                True\nChannel              True\nViews                True\nLikes                True\nComments             True\nDescription          True\nLicensed             True\nofficial_video       True\nStream               True\ndtype: bool"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:10.218270400Z",
     "start_time": "2023-12-10T18:18:10.105265900Z"
    }
   },
   "id": "9d71cd60ba7fdce7"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# fill values\n",
    "numeric_fillna = -50 # Loudness is measured in dB, min value is around -46.3\n",
    "string_fillna = '_'\n",
    "boolean_fillna = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:10.343650100Z",
     "start_time": "2023-12-10T18:18:10.214263700Z"
    }
   },
   "id": "786318d040327656"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# numeric\n",
    "dataset['Danceability'] = dataset['Danceability'].fillna(numeric_fillna)\n",
    "dataset['Energy'] = dataset['Energy'].fillna(numeric_fillna)\n",
    "dataset['Key'] = dataset['Key'].fillna(numeric_fillna)\n",
    "dataset['Loudness'] = dataset['Loudness'].fillna(numeric_fillna)\n",
    "dataset['Speechiness'] = dataset['Speechiness'].fillna(numeric_fillna)\n",
    "dataset['Acousticness'] = dataset['Acousticness'].fillna(numeric_fillna)\n",
    "dataset['Instrumentalness'] = dataset['Instrumentalness'].fillna(numeric_fillna)\n",
    "dataset['Liveness'] = dataset['Liveness'].fillna(numeric_fillna)\n",
    "dataset['Valence'] = dataset['Valence'].fillna(numeric_fillna)\n",
    "dataset['Tempo'] = dataset['Tempo'].fillna(numeric_fillna)\n",
    "dataset['Duration_ms'] = dataset['Duration_ms'].fillna(numeric_fillna)\n",
    "dataset['Views'] = dataset['Views'].fillna(numeric_fillna)\n",
    "dataset['Likes'] = dataset['Likes'].fillna(numeric_fillna)\n",
    "dataset['Comments'] = dataset['Comments'].fillna(numeric_fillna)\n",
    "dataset['Stream'] = dataset['Stream'].fillna(numeric_fillna)\n",
    "# string -> '_'\n",
    "dataset['Url_youtube'] = dataset['Url_youtube'].fillna(string_fillna)\n",
    "dataset['Title'] = dataset['Title'].fillna(string_fillna)\n",
    "dataset['Channel'] = dataset['Channel'].fillna(string_fillna)\n",
    "dataset['Description'] = dataset['Description'].fillna(string_fillna)\n",
    "# bool -> False\n",
    "dataset['Licensed'] = dataset['Licensed'].fillna(boolean_fillna)\n",
    "dataset['official_video'] = dataset['official_video'].fillna(boolean_fillna)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:10.488649700Z",
     "start_time": "2023-12-10T18:18:10.341651700Z"
    }
   },
   "id": "473c0257a5b57f70"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# make IDs explicit\n",
    "dataset['Url_spotify'] = dataset['Url_spotify'].apply(lambda uri: uri.split('/')[-1])\n",
    "dataset['Uri'] = dataset['Uri'].apply(lambda uri: uri.split(':')[-1])\n",
    "dataset['Url_youtube'] = dataset['Url_youtube'].apply(lambda uri: uri.split('?v=')[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:10.636649900Z",
     "start_time": "2023-12-10T18:18:10.487650900Z"
    }
   },
   "id": "427692559a6e9a88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also observed that some videos and some tracks have different values for the same column and in our dataset this has no sense (e.g, a video having two different ```views``` values: we don't work with the video over time, so this shouldn't happen).\n",
    "\n",
    "Videos:\n",
    "- views, likes, comments: we take the ```max``` value\n",
    "- official_video: we set it to ```false```\n",
    "\n",
    "Tracks:\n",
    "- streams: we take the ```max``` value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c74dae08c7bdba2"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.7 s, sys: 6.19 ms, total: 47.7 s\n",
      "Wall time: 47.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# dataset cleaning\n",
    "# some videos have more than one value for views, likes, comments and official_video\n",
    "# we take the max for everything but official_video, for which we just set to false\n",
    "yt_video_urls = dataset[['Url_youtube']].drop_duplicates().reset_index(drop=True)\n",
    "for index, row in yt_video_urls.iterrows():\n",
    "    # get rows with same youtube video URL\n",
    "    videos = dataset[dataset['Url_youtube'] == row['Url_youtube']]\n",
    "    # if there is more than one row\n",
    "    if len(videos) > 1:\n",
    "        # take max values\n",
    "        max_views = videos['Views'].max()\n",
    "        max_likes = videos['Likes'].max()\n",
    "        max_comments = videos['Comments'].max()\n",
    "        # check if official_video needs to be fixed \n",
    "        fix_official_video = False\n",
    "        if len(videos['official_video'].drop_duplicates()) > 1:\n",
    "            fix_official_video = True\n",
    "        # fix values\n",
    "        for row_idx in videos.index:\n",
    "            dataset.at[row_idx, 'Views'] = max_views\n",
    "            dataset.at[row_idx, 'Likes'] = max_likes\n",
    "            dataset.at[row_idx, 'Comments'] = max_comments\n",
    "            if fix_official_video:\n",
    "                dataset.at[row_idx, 'official_video'] = False\n",
    "                \n",
    "# the same thing can happen with stream of spotify song: also here we take the max value\n",
    "spotify_track_uris = dataset[['Uri']].drop_duplicates().reset_index(drop=True)\n",
    "for index, row in spotify_track_uris.iterrows():\n",
    "    # get rows with the same spotify track\n",
    "    tracks = dataset[dataset['Uri'] == row['Uri']]\n",
    "    # if there is more than one track\n",
    "    if len(tracks) > 1:\n",
    "        # take the max value and set it on all the rows\n",
    "        max_streams = tracks['Stream'].max()\n",
    "        for row_idx in tracks.index:\n",
    "            dataset.at[row_idx, 'Stream'] = max_streams"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:58.511831400Z",
     "start_time": "2023-12-10T18:18:10.638650400Z"
    }
   },
   "id": "f2b626e91083172a"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Id                  False\nAlbum                True\nTotal_tracks        False\nRelease_date        False\nAvailable_market    False\ndtype: bool"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_album.isnull().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:58.512845200Z",
     "start_time": "2023-12-10T18:18:58.511831400Z"
    }
   },
   "id": "d4487d40250acc80"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "spotify_album['Id'] = spotify_album['Id'].apply(lambda uri: uri.split(':')[-1])\n",
    "spotify_album['Album'] = spotify_album['Album'].fillna(string_fillna)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:58.733845500Z",
     "start_time": "2023-12-10T18:18:58.511831400Z"
    }
   },
   "id": "78fed90acc3a5ed7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rdflib setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e963da9ae0b06b67"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Set the countries and the SoundGraph ontologies namespaces (not known by rdflib)\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "SG = Namespace(\"https://www.dei.unipd.it/db2/ontology/soundgraph#\")\n",
    "\n",
    "# create the graph\n",
    "g = Graph()\n",
    "\n",
    "# bind the namespaces to a prefix\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"sg\", SG)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:58.875744200Z",
     "start_time": "2023-12-10T18:18:58.738757800Z"
    }
   },
   "id": "bfa59de377b09a98"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# util function to dump the graph in a file and get a new empty graph with the bindings already set\n",
    "def write_and_empty_graph(graph, filename):\n",
    "    with open(rdf_path + filename, 'w') as file:\n",
    "        file.write(graph.serialize(format='turtle'))\n",
    "        \n",
    "    graph = Graph()\n",
    "    graph.bind(\"foaf\", FOAF)\n",
    "    graph.bind(\"xsd\", XSD)\n",
    "    graph.bind(\"countries\", CNS)\n",
    "    graph.bind(\"sg\", SG)\n",
    "    return graph"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:18:59.035742400Z",
     "start_time": "2023-12-10T18:18:58.878744500Z"
    }
   },
   "id": "3d744f1559aa261f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### YouTube Video"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce0187c7c14cd7dc"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.61 s, sys: 290 ms, total: 5.9 s\n",
      "Wall time: 5.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in dataset.iterrows():\n",
    "    if row['Url_youtube'] != string_fillna:\n",
    "        video_id = 'video_' + row['Url_youtube']\n",
    "        Video = URIRef(SG[video_id])\n",
    "        g.add((Video, RDF.type, SG.YouTubeVideo))\n",
    "        \n",
    "        # data properties\n",
    "        g.add((Video, SG['videoTitle'], Literal(row['Title'], datatype=XSD.string)))\n",
    "        if row['Description'] != string_fillna:\n",
    "            g.add((Video, SG['videoDescription'], Literal(row['Description'], datatype=XSD.string)))\n",
    "        if row['Comments'] != numeric_fillna:\n",
    "            g.add((Video, SG['videoComments'], Literal(row['Comments'], datatype=XSD.integer)))\n",
    "        if row['Likes'] != numeric_fillna:\n",
    "            g.add((Video, SG['videoLikes'], Literal(row['Likes'], datatype=XSD.integer)))\n",
    "        g.add((Video, SG['videoViews'], Literal(row['Views'], datatype=XSD.integer)))\n",
    "        g.add((Video, SG['isOfficialVideo'], Literal(row['official_video'], datatype=XSD.boolean)))\n",
    "        g.add((Video, SG['isLicensed'], Literal(row['Licensed'], datatype=XSD.boolean)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:19:05.054154200Z",
     "start_time": "2023-12-10T18:18:59.039749100Z"
    }
   },
   "id": "6edaa2f6848ebb65"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### YouTube Channel + publishes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77cb5751af8980c5"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.39 s, sys: 69.9 ms, total: 9.46 s\n",
      "Wall time: 9.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in youtube_api_channels.iterrows():\n",
    "    if row['channelId'] != string_fillna:\n",
    "        channel_id = 'channel_' + row['channelId']\n",
    "        Channel = URIRef(SG[channel_id])\n",
    "        g.add((Channel, RDF.type, SG.YouTubeChannel))\n",
    "        \n",
    "        # data properties\n",
    "        g.add((Channel, SG['channelName'], Literal(row['originalChannel'], datatype=XSD.string)))\n",
    "        if row['channelDescription'] != string_fillna:\n",
    "            g.add((Channel, SG['channelDescription'], Literal(row['channelDescription'], datatype=XSD.string)))\n",
    "        g.add((Channel, SG['channelViewCount'], Literal(row['viewCount'], datatype=XSD.integer)))\n",
    "        g.add((Channel, SG['channelSubscribersCount'], Literal(row['subscriberCount'], datatype=XSD.integer)))\n",
    "        g.add((Channel, SG['channelVideoCount'], Literal(row['videoCount'], datatype=XSD.integer)))\n",
    "        \n",
    "        # obj properties\n",
    "        published_videos = dataset[dataset['Channel'] == row['originalChannel']]['Url_youtube']\n",
    "        for video_url in published_videos:\n",
    "                Video = URIRef('video_' + SG[video_url])\n",
    "                g.add((Channel, SG['publishes'], Video))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:19:14.516961600Z",
     "start_time": "2023-12-10T18:19:05.053154200Z"
    }
   },
   "id": "7a9109a4f0c1c2a6"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.7 s, sys: 99.8 ms, total: 4.8 s\n",
      "Wall time: 4.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = write_and_empty_graph(g, 'rdflib_youtube.ttl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:19:19.342967300Z",
     "start_time": "2023-12-10T18:19:14.516961600Z"
    }
   },
   "id": "a1a797cf529feebc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SpotifyTrack + isRelatedTo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62a618e9634d3906"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.98 s, sys: 144 ms, total: 9.13 s\n",
      "Wall time: 9.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in dataset.iterrows():\n",
    "    track_uri = 'track_' + row['Uri']\n",
    "    Track = URIRef(SG[track_uri])\n",
    "    g.add((Track, RDF.type, SG.SpotifyTrack))\n",
    "    \n",
    "    # data properties\n",
    "    g.add((Track, SG['trackName'], Literal(row['Track'], datatype=XSD.string)))\n",
    "    if row['Duration_ms'] != numeric_fillna:\n",
    "        g.add((Track, SG['trackAcousticness'], Literal(row['Acousticness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackDanceability'], Literal(row['Danceability'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackDuration'], Literal(row['Duration_ms'], datatype=XSD.integer)))\n",
    "        g.add((Track, SG['trackEnergy'], Literal(row['Energy'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackInstrumentalness'], Literal(row['Instrumentalness'], datatype=XSD.float)))    \n",
    "        g.add((Track, SG['trackKey'], Literal(row['Key'], datatype=XSD.integer)))\n",
    "        g.add((Track, SG['trackLiveness'], Literal(row['Liveness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackLoudness'], Literal(row['Loudness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackSpeechiness'], Literal(row['Speechiness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackTempo'], Literal(row['Tempo'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackValence'], Literal(row['Valence'], datatype=XSD.float)))\n",
    "    if row['Stream'] != numeric_fillna:\n",
    "        g.add((Track, SG['trackStreams'], Literal(row['Stream'], datatype=XSD.integer)))\n",
    "    \n",
    "    # object properties\n",
    "    # isRelatedTo\n",
    "    if row['Url_youtube'] != string_fillna:\n",
    "        video_uri = 'video_' + row['Url_youtube']\n",
    "        Video = URIRef(SG[video_uri])\n",
    "        g.add((Track, SG['isRelatedTo'], Video))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:19:28.513695800Z",
     "start_time": "2023-12-10T18:19:19.341966700Z"
    }
   },
   "id": "4353c3e9136673e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SpotifyAlbum + containsTrack + isAvailableIn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19ec33b2ccdb925f"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.4 s, sys: 850 ms, total: 39.3 s\n",
      "Wall time: 39.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in spotify_album.iterrows():\n",
    "    album_uri = 'album_' + row['Id']\n",
    "    Album = URIRef(SG[album_uri])\n",
    "    g.add((Album, RDF.type, SG.SpotifyAlbum))\n",
    "    \n",
    "    # data prop\n",
    "    g.add((Album, SG['albumName'], Literal(row['Album'], datatype=XSD.string)))\n",
    "    if row['Release_date'] != '0000':\n",
    "        g.add((Album, SG['albumReleaseDate'], Literal(row['Release_date'], datatype=XSD.date)))\n",
    "    g.add((Album, SG['albumTotalTracksNum'], Literal(row['Total_tracks'], datatype=XSD.integer)))\n",
    "    g.add((Album, SG['albumType'], Literal(dataset.at[index, 'Album_type'], datatype=XSD.string))) # TODO check enum datatype\n",
    "    \n",
    "    # obj prop\n",
    "    # isAvailableIn\n",
    "    market_list = ast.literal_eval(row['Available_market']) # converts the string representation of a list into an object of type list\n",
    "    for market in market_list:\n",
    "        Country = URIRef(CNS[market.lower()])\n",
    "        g.add((Album, SG['isAvailableIn'], Country))\n",
    "        \n",
    "    # containsTrack\n",
    "    Track = URIRef(SG['track_' + dataset.at[index, 'Uri']])\n",
    "    g.add((Album, SG['containsTrack'], Track))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:20:07.731511400Z",
     "start_time": "2023-12-10T18:19:28.493680100Z"
    }
   },
   "id": "99971ea56231ce6a"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.2 s, sys: 140 ms, total: 33.3 s\n",
      "Wall time: 33.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = write_and_empty_graph(g, 'rdflib_spotify_album_track.ttl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:20:41.137714300Z",
     "start_time": "2023-12-10T18:20:07.727515200Z"
    }
   },
   "id": "45b42d68234b6d81"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Artist + hasNationality + Genre + hasGenre + composes + writes + performsIn + hasOfficialChannel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c2b6908af173c37"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.3 s, sys: 130 ms, total: 21.5 s\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in wikidata_artists.iterrows():\n",
    "    row_spotify_artist_info = spotify_artist_info.iloc[index] # one row\n",
    "    rows_dataset = dataset[dataset['Url_spotify'] == row['Url_spotify']] # 10 rows\n",
    "    \n",
    "    artist_uri = \"artist_\" + row['Url_spotify']\n",
    "    Artist = URIRef(SG[artist_uri])\n",
    "    g.add((Artist, RDF.type, SG.SpotifyArtist))\n",
    "    \n",
    "    # data properties\n",
    "    g.add((Artist, SG['artistFollowersNum'], Literal(row_spotify_artist_info['Followers'], datatype=XSD.integer)))\n",
    "    g.add((Artist, SG['artistName'], Literal(row['Artist'], datatype=XSD.string)))\n",
    "    g.add((Artist, SG['artistPopularity'], Literal(row_spotify_artist_info['Popularity'], datatype=XSD.integer)))\n",
    "    if row['websiteLabel'] != '_':\n",
    "        g.add((Artist, SG['artistWebsite'], Literal(row['websiteLabel'], datatype=XSD.string)))\n",
    "    if row['start'] != '_':\n",
    "        g.add((Artist, SG['startWorkingPeriod'], Literal(row['start'], datatype=XSD.gYear)))\n",
    "    if row['end'] != '_':\n",
    "        g.add((Artist, SG['endWorkingPeriod'], Literal(row['end'], datatype=XSD.gYear)))\n",
    "    if row['dissolved'] != '_':\n",
    "        g.add((Artist, SG['dissolvedIn'], Literal(row['dissolved'], datatype=XSD.gYear)))\n",
    "    \n",
    "    # obj prop\n",
    "    # hasNationality\n",
    "    if row['country_codes'] != '_':\n",
    "        cc_list = row['country_codes'].split('+')\n",
    "        for cc in cc_list:\n",
    "            Country = URIRef(CNS[cc.lower()])\n",
    "            g.add((Artist, SG['hasNationality'], Country))\n",
    "    \n",
    "    # Genre + hasGenre\n",
    "    artist_genre_list = ast.literal_eval(row_spotify_artist_info['Genres'])\n",
    "    for genre_name in artist_genre_list:\n",
    "        genre_uri = 'genre_' + re.sub('[^A-Za-z0-9\\s]', '', genre_name).replace(' ', '_')\n",
    "        Genre = URIRef(SG[genre_uri])\n",
    "        g.add((Genre, RDF.type, SG.Genre))\n",
    "        g.add((Artist, SG['hasGenre'], Genre))\n",
    "     \n",
    "    for index2, row2 in rows_dataset.iterrows():\n",
    "        # composes\n",
    "        album_uri = 'album_' + spotify_album.iloc[index2]['Id']\n",
    "        Album = URIRef(SG[album_uri])\n",
    "        g.add((Artist, SG['composes'], Album))\n",
    "        \n",
    "        # writes\n",
    "        track_uri = 'track_' + row2['Uri']\n",
    "        Track = URIRef(SG[track_uri])\n",
    "        g.add((Artist, SG['writes'], Track))\n",
    "        \n",
    "        # performsIn\n",
    "        if row2['Url_youtube'] != string_fillna:\n",
    "            video_uri = 'video_' + row2['Url_youtube']\n",
    "            Video = URIRef(SG[video_uri])\n",
    "            g.add((Artist, SG['performsIn'], Video))\n",
    "        \n",
    "        # hasOfficialChannel\n",
    "        if row2['Channel'] != string_fillna and row2['official_video']:\n",
    "            yt_channel_row = youtube_api_channels[youtube_api_channels['originalChannel'] == row2['Channel']].iloc[0]\n",
    "            \n",
    "            channel_uri = 'channel_' + yt_channel_row['channelId']\n",
    "            Channel = URIRef(SG[channel_uri])\n",
    "            \n",
    "            g.add((Artist, SG['hasOfficialChannel'], Channel))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:21:02.612167200Z",
     "start_time": "2023-12-10T18:20:41.137714300Z"
    }
   },
   "id": "43b8d2306297067a"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.68 s, sys: 10 ms, total: 1.69 s\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = write_and_empty_graph(g, 'rdflib_spotify_artist_genre.ttl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:21:04.351362Z",
     "start_time": "2023-12-10T18:21:02.606256300Z"
    }
   },
   "id": "905ce0dfa3408f47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Awards + hasReceived"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "364101c6728f24"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 450 ms, sys: 20.1 ms, total: 470 ms\n",
      "Wall time: 460 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in wikidata_awards_statements.iterrows():\n",
    "    award_id = 'award_' + str(index)\n",
    "    \n",
    "    Award = URIRef(SG[award_id])\n",
    "    Artist = URIRef(SG['artist_' + row['artist_spotify_id']])\n",
    "    \n",
    "    award_data = wikidata_awards[wikidata_awards['award_id'] == row['award_id']].iloc[0]\n",
    "    award_class_year = award_data['award_class'] + (row['award_year'] if row['award_year'] != '_' else '')\n",
    "    \n",
    "    g.add((Award, RDF.type, SG[award_class_year]))\n",
    "    \n",
    "    # data properties\n",
    "    g.add((Award, SG['awardName'], Literal(award_data['award_type'], datatype=XSD.string)))\n",
    "    if award_data['award_category'] != '_':\n",
    "        g.add((Award, SG['awardCategory'], Literal(award_data['award_category'], datatype=XSD.string)))\n",
    "    if row['award_year'] != '_':\n",
    "        g.add((Award, SG['awardYear'], Literal(row['award_year'], datatype=XSD.gYear)))\n",
    "    \n",
    "    # object properties\n",
    "    # hasReceived\n",
    "    g.add((Artist, SG['hasReceived'], Award))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:21:04.772362Z",
     "start_time": "2023-12-10T18:21:04.411362100Z"
    }
   },
   "id": "90a41a280e7e9e92"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96.7 ms, sys: 10.1 ms, total: 107 ms\n",
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = write_and_empty_graph(g, 'rdflib_awards.ttl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:21:04.938360Z",
     "start_time": "2023-12-10T18:21:04.768361600Z"
    }
   },
   "id": "cd596662dfc48ef8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "db2",
   "language": "python",
   "display_name": "db2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
