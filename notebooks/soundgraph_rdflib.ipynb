{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Spotify and YouTube dataset population\n",
    "\n",
    "This notebook outlines the steps to create an RDF dataset based on the SoundGraph ontology, from the data import to RDF triple export in Turtle format."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e953e7e47cdd4d59"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# required libraries\n",
    "from pathlib import Path\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "from rdflib.namespace import FOAF, XSD\n",
    "import os\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:50:54.124635900Z",
     "start_time": "2023-12-07T22:50:53.828407800Z"
    }
   },
   "id": "ad98a76565745715"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load CSV files + preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1528fda7473d7cb9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# csv files path\n",
    "base_path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "\n",
    "dataset_path = base_path + '/data/Spotify_Youtube.csv'\n",
    "spotify_artist_path = base_path + '/data/Artists.csv'\n",
    "spotify_artist_info_path = base_path + '/data/Artist_info.csv'\n",
    "spotify_album_path = base_path + '/data/Album_info.csv'\n",
    "wikidata_artists_path = base_path + '/data/wikidata_artists.csv'\n",
    "wikidata_award_statements_path = base_path + '/data/wikidata_award_statements.csv'\n",
    "wikidata_awards_path = base_path + '/data/wikidata_awards_processed.csv'\n",
    "youtube_api_channels_path = base_path + '/data/youtubeapi_channels_complete.csv'\n",
    "# target path where to save the serializations\n",
    "rdf_path = base_path + '/rdf/' "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T22:50:58.433241600Z",
     "start_time": "2023-12-07T22:50:58.427242100Z"
    }
   },
   "id": "4381a254bd1b04c6"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20718 entries, 0 to 20717\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        20718 non-null  int64  \n",
      " 1   Artist            20718 non-null  object \n",
      " 2   Url_spotify       20718 non-null  object \n",
      " 3   Track             20718 non-null  object \n",
      " 4   Album             20718 non-null  object \n",
      " 5   Album_type        20718 non-null  object \n",
      " 6   Uri               20718 non-null  object \n",
      " 7   Danceability      20716 non-null  float64\n",
      " 8   Energy            20716 non-null  float64\n",
      " 9   Key               20716 non-null  float64\n",
      " 10  Loudness          20716 non-null  float64\n",
      " 11  Speechiness       20716 non-null  float64\n",
      " 12  Acousticness      20716 non-null  float64\n",
      " 13  Instrumentalness  20716 non-null  float64\n",
      " 14  Liveness          20716 non-null  float64\n",
      " 15  Valence           20716 non-null  float64\n",
      " 16  Tempo             20716 non-null  float64\n",
      " 17  Duration_ms       20716 non-null  float64\n",
      " 18  Url_youtube       20248 non-null  object \n",
      " 19  Title             20248 non-null  object \n",
      " 20  Channel           20248 non-null  object \n",
      " 21  Views             20248 non-null  float64\n",
      " 22  Likes             20177 non-null  float64\n",
      " 23  Comments          20149 non-null  float64\n",
      " 24  Description       19842 non-null  object \n",
      " 25  Licensed          20248 non-null  object \n",
      " 26  official_video    20248 non-null  object \n",
      " 27  Stream            20142 non-null  float64\n",
      "dtypes: float64(15), int64(1), object(12)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(dataset_path)\n",
    "# TODO custom .fillna() for each column\n",
    "# TODO split()[-1] ids\n",
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T23:07:28.420203300Z",
     "start_time": "2023-12-07T23:07:27.980308900Z"
    }
   },
   "id": "b7a19baa75751bc4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data cleaning\n",
    "We observed that some videos and some tracks have different values for the same column and in our dataset this has no sense (e.g, a video having two different ```views``` values: we don't work with the video over time, so this shouldn't happen).\n",
    "\n",
    "Videos:\n",
    "- views, likes, comments: we take the ```max``` value\n",
    "- official_video: we set it to ```false```\n",
    "\n",
    "Tracks:\n",
    "- streams: we take the ```max``` value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cd99741f827a029"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.9 s, sys: 10.3 ms, total: 37.9 s\n",
      "Wall time: 37.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# dataset cleaning\n",
    "# some videos have more than one value for views, likes, comments and official_video\n",
    "# we take the max for everything but official_video, for which we just set to false\n",
    "yt_video_urls = dataset[['Url_youtube']].drop_duplicates().reset_index(drop=True)\n",
    "for index, row in yt_video_urls.iterrows():\n",
    "    # get rows with same youtube video URL\n",
    "    videos = dataset[dataset['Url_youtube'] == row['Url_youtube']]\n",
    "    # if there is more than one row\n",
    "    if len(videos) > 1:\n",
    "        # take max values\n",
    "        max_views = videos['Views'].max()\n",
    "        max_likes = videos['Likes'].max()\n",
    "        max_comments = videos['Comments'].max()\n",
    "        # check if official_video needs to be fixed \n",
    "        fix_official_video = False\n",
    "        if len(videos['official_video'].drop_duplicates()) > 1:\n",
    "            fix_official_video = True\n",
    "        # fix values\n",
    "        for row_idx in videos.index:\n",
    "            dataset.at[row_idx, 'Views'] = max_views\n",
    "            dataset.at[row_idx, 'Likes'] = max_likes\n",
    "            dataset.at[row_idx, 'Comments'] = max_comments\n",
    "            if fix_official_video:\n",
    "                dataset.at[row_idx, 'official_video'] = False\n",
    "                \n",
    "# the same thing can happen with stream of spotify song: also here we take the max value\n",
    "spotify_track_uris = dataset[['Uri']].drop_duplicates().reset_index(drop=True)\n",
    "for index, row in spotify_track_uris.iterrows():\n",
    "    # get rows with the same spotify track\n",
    "    tracks = dataset[dataset['Uri'] == row['Uri']]\n",
    "    # if there is more than one track\n",
    "    if len(tracks) > 1:\n",
    "        # take the max value and set it on all the rows\n",
    "        max_streams = tracks['Stream'].max()\n",
    "        for row_idx in tracks.index:\n",
    "            dataset.at[row_idx, 'Stream'] = max_streams"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T23:06:17.674732100Z",
     "start_time": "2023-12-07T23:05:39.699257Z"
    }
   },
   "id": "b94e7ceb34520712"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO check if other files need some preprocessing (on ids, list to string, idk), basta che li facciamo tutti qui così poi viene più easy sotto"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d6cc52c597d847c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO ma questo csv serve?\n",
    "spotify_artist = pd.read_csv(spotify_artist_path)\n",
    "spotify_artist.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74157c4f5452cfd5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spotify_artist_info = pd.read_csv(spotify_artist_path)\n",
    "spotify_artist_info.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebe1d7fbe7063034"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wikidata_artist = pd.read_csv(wikidata_artists_path)\n",
    "wikidata_artist.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5eda0d275249da10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spotify_album = pd.read_csv(spotify_album_path)\n",
    "spotify_album.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffbecdb820942b89"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "youtube_api_channels = pd.read_csv(youtube_api_channels_path)\n",
    "youtube_api_channels.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad49c57f8805d84e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wikidata_awards = pd.read_csv(wikidata_awards_path)\n",
    "wikidata_awards.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70147b3d8307e1a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wikidata_awards_statements = pd.read_csv(wikidata_award_statements_path)\n",
    "wikidata_awards_statements.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84029d3d90891f8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rdflib setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e963da9ae0b06b67"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Set the countries and the SoundGraph ontologies namespaces (not known by rdflib)\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "SG = Namespace(\"https://www.dei.unipd.it/db2/ontology/soundgraph#\")\n",
    "\n",
    "# create the graph\n",
    "g = Graph()\n",
    "\n",
    "# bind the namespaces to a prefix\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"sg\", SG)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfa59de377b09a98"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# util function to dump the graph in a file and get a new empty graph with the bindings already set\n",
    "def write_and_empty_graph(graph, filename):\n",
    "    with open(rdf_path + filename, 'w') as file:\n",
    "        file.write(graph.serialize(format='turtle'))\n",
    "        \n",
    "    graph = Graph()\n",
    "    graph.bind(\"foaf\", FOAF)\n",
    "    graph.bind(\"xsd\", XSD)\n",
    "    graph.bind(\"countries\", CNS)\n",
    "    graph.bind(\"sg\", SG)\n",
    "    return graph"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d744f1559aa261f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO rdflib"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d310a2c165362c40"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "db2",
   "language": "python",
   "display_name": "db2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
