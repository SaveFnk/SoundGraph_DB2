{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify and YouTube dataset population\n",
    "\n",
    "This notebook outlines the steps to create an RDF dataset based on the SoundGraph ontology, from the data import to RDF triple export in Turtle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:17:39.249733200Z",
     "start_time": "2023-11-27T14:17:38.779832700Z"
    }
   },
   "outputs": [],
   "source": [
    "# required library\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:11:15.193772600Z",
     "start_time": "2023-11-27T14:11:15.193772600Z"
    }
   },
   "outputs": [],
   "source": [
    "# csv files path\n",
    "dataset_path='../data/Spotify_Youtube.csv'\n",
    "spotify_artist_path = '../data/Artists.csv'\n",
    "spotify_artist_info_path = '../data/Artist_info.csv'\n",
    "spotify_album_path = '../data/Album_info.csv'\n",
    "wikidata_artists_path = '../data/wikidata_artists.csv'\n",
    "wikidata_award_statements_path = '../data/wikidata_award_statements.csv'\n",
    "wikidata_awards_path = '../data/wikidata_awards.csv'\n",
    "youtube_api_channels_path = '../data/youtubeapi_channels_complete.csv'\n",
    "# target folder where to save the output\n",
    "targetFolder = '../rdf/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:11:16.784804Z",
     "start_time": "2023-11-27T14:11:15.193772600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20718 entries, 0 to 20717\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        20718 non-null  int64  \n",
      " 1   Artist            20718 non-null  object \n",
      " 2   Url_spotify       20718 non-null  object \n",
      " 3   Track             20718 non-null  object \n",
      " 4   Album             20718 non-null  object \n",
      " 5   Album_type        20718 non-null  object \n",
      " 6   Uri               20718 non-null  object \n",
      " 7   Danceability      20716 non-null  float64\n",
      " 8   Energy            20716 non-null  float64\n",
      " 9   Key               20716 non-null  float64\n",
      " 10  Loudness          20716 non-null  float64\n",
      " 11  Speechiness       20716 non-null  float64\n",
      " 12  Acousticness      20716 non-null  float64\n",
      " 13  Instrumentalness  20716 non-null  float64\n",
      " 14  Liveness          20716 non-null  float64\n",
      " 15  Valence           20716 non-null  float64\n",
      " 16  Tempo             20716 non-null  float64\n",
      " 17  Duration_ms       20716 non-null  float64\n",
      " 18  Url_youtube       20248 non-null  object \n",
      " 19  Title             20248 non-null  object \n",
      " 20  Channel           20248 non-null  object \n",
      " 21  Views             20248 non-null  float64\n",
      " 22  Likes             20177 non-null  float64\n",
      " 23  Comments          20149 non-null  float64\n",
      " 24  Description       19842 non-null  object \n",
      " 25  Licensed          20248 non-null  object \n",
      " 26  official_video    20248 non-null  object \n",
      " 27  Stream            20142 non-null  float64\n",
      "dtypes: float64(15), int64(1), object(12)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# load the songs \n",
    "dataset = pd.read_csv(dataset_path, sep=',')\n",
    "# preprocessing of URLs, needed to get uri\n",
    "#dataset['Url_spotify'] = dataset['Url_spotify'].fillna('_').apply(lambda uri: uri.split(':')[-1]) \n",
    "#dataset['Uri'] = dataset['Uri'].fillna('_').apply(lambda uri: uri.split(':')[-1]) \n",
    "#dataset['Album'] = dataset['Album'].fillna('_').apply(lambda uri: uri.split(':')[-1]) \n",
    "#dataset['Url_youtube'] = dataset['Url_youtube'].fillna('_').apply(lambda uri: uri.split('?v=')[-1]) \n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:11:16.947368400Z",
     "start_time": "2023-11-27T14:11:16.784804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2079 entries, 0 to 2078\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  2079 non-null   int64 \n",
      " 1   Artist      2079 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 32.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the artists present\n",
    "spotify_artist = pd.read_csv(spotify_artist_path, sep=',')\n",
    "spotify_artist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:25:43.362316500Z",
     "start_time": "2023-11-27T14:25:43.296517600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2079 entries, 0 to 2078\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Artist      2079 non-null   object\n",
      " 1   Followers   2079 non-null   int64 \n",
      " 2   Genres      2079 non-null   object\n",
      " 3   Popularity  2079 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 65.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# load spotify artists information\n",
    "spotify_artist_info = pd.read_csv(spotify_artist_info_path, sep=',')\n",
    "spotify_artist_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:11:17.789073500Z",
     "start_time": "2023-11-27T14:11:17.100964100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20718 entries, 0 to 20717\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Id                20718 non-null  object\n",
      " 1   Album             20641 non-null  object\n",
      " 2   Total_tracks      20718 non-null  int64 \n",
      " 3   Release_date      20718 non-null  object\n",
      " 4   Available_market  20718 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 809.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# load spotify album information\n",
    "spotify_album = pd.read_csv(spotify_album_path, sep=',')\n",
    "spotify_album.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:11:17.919366100Z",
     "start_time": "2023-11-27T14:11:17.789073500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2079 entries, 0 to 2078\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Artist         2079 non-null   object\n",
      " 1   Url_spotify    2079 non-null   object\n",
      " 2   artistLabel    2079 non-null   object\n",
      " 3   websiteLabel   2079 non-null   object\n",
      " 4   start          2079 non-null   object\n",
      " 5   end            2079 non-null   object\n",
      " 6   dissolved      2079 non-null   object\n",
      " 7   country_codes  2079 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 130.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the wikidata artists information\n",
    "wikidata_artists = pd.read_csv(wikidata_artists_path, sep=',')\n",
    "wikidata_artists.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:11:18.033805100Z",
     "start_time": "2023-11-27T14:11:17.902183200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1035 entries, 0 to 1034\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   artist_spotify_id  1035 non-null   object\n",
      " 1   award_id           1035 non-null   int64 \n",
      " 2   award_year         1035 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 24.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the wikidata award statements information\n",
    "wikidata_award_statements = pd.read_csv(wikidata_award_statements_path, sep=',')\n",
    "wikidata_award_statements.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:11:18.149855400Z",
     "start_time": "2023-11-27T14:11:18.033805100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 193 entries, 0 to 192\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   award_id        193 non-null    int64 \n",
      " 1   award_name      193 non-null    object\n",
      " 2   award_type      193 non-null    object\n",
      " 3   award_category  118 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 6.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the wikidata awards information\n",
    "wikidata_awards = pd.read_csv(wikidata_awards_path,sep=',')\n",
    "wikidata_awards.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:11:18.439196800Z",
     "start_time": "2023-11-27T14:11:18.149855400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6715 entries, 0 to 6714\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   channelId           6715 non-null   object\n",
      " 1   title               6715 non-null   object\n",
      " 2   channelDescription  4241 non-null   object\n",
      " 3   viewCount           6715 non-null   object\n",
      " 4   subscriberCount     6715 non-null   object\n",
      " 5   videoCount          6715 non-null   object\n",
      " 6   error               6715 non-null   int64 \n",
      " 7   originalChannel     6715 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 419.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the youtube channels information\n",
    "youtube_api_channels = pd.read_csv(youtube_api_channels_path, sep=',')\n",
    "youtube_api_channels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### DataFrames for obj prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:11:18.518537500Z",
     "start_time": "2023-11-27T14:11:18.439196800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>album_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3AA28KZvwAUcZuOKwyblJQ</td>\n",
       "      <td>0bUTHlWbkSQysoM3VsWldT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3AA28KZvwAUcZuOKwyblJQ</td>\n",
       "      <td>2dIGnmEIy1WZIcZCFSj6i8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3AA28KZvwAUcZuOKwyblJQ</td>\n",
       "      <td>4V9YFKLqZ5h8nQFTvDQscC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3AA28KZvwAUcZuOKwyblJQ</td>\n",
       "      <td>2dIGnmEIy1WZIcZCFSj6i8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3AA28KZvwAUcZuOKwyblJQ</td>\n",
       "      <td>0YvYmLBFFwYxgI4U9KKgUm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20713</th>\n",
       "      <td>3EYY5FwDkHEYLw5V86SAtl</td>\n",
       "      <td>7o5cIYGdDmDqa9gGNsU60e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714</th>\n",
       "      <td>3EYY5FwDkHEYLw5V86SAtl</td>\n",
       "      <td>2JR4Wct66k7JOEh6y5yy0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20715</th>\n",
       "      <td>3EYY5FwDkHEYLw5V86SAtl</td>\n",
       "      <td>7v9knMsQE5CkN2HE4yhIQu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20716</th>\n",
       "      <td>3EYY5FwDkHEYLw5V86SAtl</td>\n",
       "      <td>3xynK8Rwi02G6VKcb15rFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20717</th>\n",
       "      <td>3EYY5FwDkHEYLw5V86SAtl</td>\n",
       "      <td>6Kj90CxlnIB4bYECjGnbGp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20718 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    artist_id                album_id\n",
       "0      3AA28KZvwAUcZuOKwyblJQ  0bUTHlWbkSQysoM3VsWldT\n",
       "1      3AA28KZvwAUcZuOKwyblJQ  2dIGnmEIy1WZIcZCFSj6i8\n",
       "2      3AA28KZvwAUcZuOKwyblJQ  4V9YFKLqZ5h8nQFTvDQscC\n",
       "3      3AA28KZvwAUcZuOKwyblJQ  2dIGnmEIy1WZIcZCFSj6i8\n",
       "4      3AA28KZvwAUcZuOKwyblJQ  0YvYmLBFFwYxgI4U9KKgUm\n",
       "...                       ...                     ...\n",
       "20713  3EYY5FwDkHEYLw5V86SAtl  7o5cIYGdDmDqa9gGNsU60e\n",
       "20714  3EYY5FwDkHEYLw5V86SAtl  2JR4Wct66k7JOEh6y5yy0L\n",
       "20715  3EYY5FwDkHEYLw5V86SAtl  7v9knMsQE5CkN2HE4yhIQu\n",
       "20716  3EYY5FwDkHEYLw5V86SAtl  3xynK8Rwi02G6VKcb15rFJ\n",
       "20717  3EYY5FwDkHEYLw5V86SAtl  6Kj90CxlnIB4bYECjGnbGp\n",
       "\n",
       "[20718 rows x 2 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# composes - isComposedBy\n",
    "composes_df = pd.DataFrame({\n",
    "    'artist_id': dataset['Url_spotify'],\n",
    "    'album_id': spotify_album['Id']\n",
    "})\n",
    "composes_df['artist_id'] = composes_df['artist_id'].apply(lambda uri: uri.split('/')[-1])\n",
    "composes_df['album_id'] = composes_df['album_id'].apply(lambda uri: uri.split(':')[-1])\n",
    "composes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:11:18.703661400Z",
     "start_time": "2023-11-27T14:11:18.518537500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3AA28KZvwAUcZuOKwyblJQ</td>\n",
       "      <td>0d28khcov6AiegSCpG5TuT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3AA28KZvwAUcZuOKwyblJQ</td>\n",
       "      <td>1foMv2HQwfQ2vntFf9HFeG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3AA28KZvwAUcZuOKwyblJQ</td>\n",
       "      <td>64dLd6rVqDLtkXFYrEUHIU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3AA28KZvwAUcZuOKwyblJQ</td>\n",
       "      <td>0q6LuUqGLUiCPP1cbdwFs3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3AA28KZvwAUcZuOKwyblJQ</td>\n",
       "      <td>7yMiX7n9SBvadzox8T5jzT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20713</th>\n",
       "      <td>3EYY5FwDkHEYLw5V86SAtl</td>\n",
       "      <td>0RtcKQGyI4hr8FgFH1TuYG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714</th>\n",
       "      <td>3EYY5FwDkHEYLw5V86SAtl</td>\n",
       "      <td>3rHvPA8lUnPBkaLyPOc0VV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20715</th>\n",
       "      <td>3EYY5FwDkHEYLw5V86SAtl</td>\n",
       "      <td>4jk00YxPtPbhvHJE9N4ddv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20716</th>\n",
       "      <td>3EYY5FwDkHEYLw5V86SAtl</td>\n",
       "      <td>5EyErbpsugWliX006eTDex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20717</th>\n",
       "      <td>3EYY5FwDkHEYLw5V86SAtl</td>\n",
       "      <td>6lOn0jz1QpjcWeXo1oMm0k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20718 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    artist_id                track_id\n",
       "0      3AA28KZvwAUcZuOKwyblJQ  0d28khcov6AiegSCpG5TuT\n",
       "1      3AA28KZvwAUcZuOKwyblJQ  1foMv2HQwfQ2vntFf9HFeG\n",
       "2      3AA28KZvwAUcZuOKwyblJQ  64dLd6rVqDLtkXFYrEUHIU\n",
       "3      3AA28KZvwAUcZuOKwyblJQ  0q6LuUqGLUiCPP1cbdwFs3\n",
       "4      3AA28KZvwAUcZuOKwyblJQ  7yMiX7n9SBvadzox8T5jzT\n",
       "...                       ...                     ...\n",
       "20713  3EYY5FwDkHEYLw5V86SAtl  0RtcKQGyI4hr8FgFH1TuYG\n",
       "20714  3EYY5FwDkHEYLw5V86SAtl  3rHvPA8lUnPBkaLyPOc0VV\n",
       "20715  3EYY5FwDkHEYLw5V86SAtl  4jk00YxPtPbhvHJE9N4ddv\n",
       "20716  3EYY5FwDkHEYLw5V86SAtl  5EyErbpsugWliX006eTDex\n",
       "20717  3EYY5FwDkHEYLw5V86SAtl  6lOn0jz1QpjcWeXo1oMm0k\n",
       "\n",
       "[20718 rows x 2 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# writes - isWrittenBy\n",
    "writes_df = pd.DataFrame({\n",
    "    'artist_id': composes_df['artist_id'],\n",
    "    'track_id': dataset['Uri'].apply(lambda uri: uri.split(':')[-1])\n",
    "})\n",
    "writes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:11:18.865992500Z",
     "start_time": "2023-11-27T14:11:18.665688300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0bUTHlWbkSQysoM3VsWldT</td>\n",
       "      <td>0d28khcov6AiegSCpG5TuT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dIGnmEIy1WZIcZCFSj6i8</td>\n",
       "      <td>1foMv2HQwfQ2vntFf9HFeG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4V9YFKLqZ5h8nQFTvDQscC</td>\n",
       "      <td>64dLd6rVqDLtkXFYrEUHIU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2dIGnmEIy1WZIcZCFSj6i8</td>\n",
       "      <td>0q6LuUqGLUiCPP1cbdwFs3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0YvYmLBFFwYxgI4U9KKgUm</td>\n",
       "      <td>7yMiX7n9SBvadzox8T5jzT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20713</th>\n",
       "      <td>7o5cIYGdDmDqa9gGNsU60e</td>\n",
       "      <td>0RtcKQGyI4hr8FgFH1TuYG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714</th>\n",
       "      <td>2JR4Wct66k7JOEh6y5yy0L</td>\n",
       "      <td>3rHvPA8lUnPBkaLyPOc0VV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20715</th>\n",
       "      <td>7v9knMsQE5CkN2HE4yhIQu</td>\n",
       "      <td>4jk00YxPtPbhvHJE9N4ddv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20716</th>\n",
       "      <td>3xynK8Rwi02G6VKcb15rFJ</td>\n",
       "      <td>5EyErbpsugWliX006eTDex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20717</th>\n",
       "      <td>6Kj90CxlnIB4bYECjGnbGp</td>\n",
       "      <td>6lOn0jz1QpjcWeXo1oMm0k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20718 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     album_id                track_id\n",
       "0      0bUTHlWbkSQysoM3VsWldT  0d28khcov6AiegSCpG5TuT\n",
       "1      2dIGnmEIy1WZIcZCFSj6i8  1foMv2HQwfQ2vntFf9HFeG\n",
       "2      4V9YFKLqZ5h8nQFTvDQscC  64dLd6rVqDLtkXFYrEUHIU\n",
       "3      2dIGnmEIy1WZIcZCFSj6i8  0q6LuUqGLUiCPP1cbdwFs3\n",
       "4      0YvYmLBFFwYxgI4U9KKgUm  7yMiX7n9SBvadzox8T5jzT\n",
       "...                       ...                     ...\n",
       "20713  7o5cIYGdDmDqa9gGNsU60e  0RtcKQGyI4hr8FgFH1TuYG\n",
       "20714  2JR4Wct66k7JOEh6y5yy0L  3rHvPA8lUnPBkaLyPOc0VV\n",
       "20715  7v9knMsQE5CkN2HE4yhIQu  4jk00YxPtPbhvHJE9N4ddv\n",
       "20716  3xynK8Rwi02G6VKcb15rFJ  5EyErbpsugWliX006eTDex\n",
       "20717  6Kj90CxlnIB4bYECjGnbGp  6lOn0jz1QpjcWeXo1oMm0k\n",
       "\n",
       "[20718 rows x 2 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# containsTrack - isInAlbum\n",
    "containsTrack_df = pd.DataFrame({\n",
    "    'album_id': composes_df['album_id'],\n",
    "    'track_id': writes_df['track_id']\n",
    "})\n",
    "containsTrack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:23:16.022835800Z",
     "start_time": "2023-11-27T14:23:15.786223200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alternative hip hop', 'modern rock', 'rock']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_string = \"['alternative hip hop', 'modern rock', 'rock']\"\n",
    "ast.literal_eval(list_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T14:12:17.373331200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 2079 entries, 0 to 2078\n",
      "Series name: Genres\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "2079 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 16.4+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "genres_df = spotify_artist_info['Genres'].copy(deep=True)\n",
    "genres_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:13:50.160117700Z",
     "start_time": "2023-11-27T14:13:50.136084500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genres_df = genres_df.apply(lambda gs: ast.literal_eval(gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:16:00.944684Z",
     "start_time": "2023-11-27T14:16:00.487177600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"children's music\""
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_df.iloc[309][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDFLib import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To use RDFLib, the following installation is required:\n",
    "\n",
    "<code>pip3 install rdflib</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T14:35:01.299051600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# rdflib knows about some namespaces, like FOAF\n",
    "from rdflib.namespace import FOAF, XSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T15:37:32.657465800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct the countries and the SoundGraph ontology namespaces not known by RDFlib\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "SG = Namespace(\"https://www.dei.unipd.it/db2/ontology/soundgraph#\")\n",
    "\n",
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"sg\", SG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T15:37:34.190250200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_and_empty_graph(graph, filename):\n",
    "    with open(targetFolder + filename, 'w') as file:\n",
    "        file.write(graph.serialize(format='turtle'))\n",
    "        \n",
    "    graph = Graph()\n",
    "    graph.bind(\"foaf\", FOAF)\n",
    "    graph.bind(\"xsd\", XSD)\n",
    "    graph.bind(\"countries\", CNS)\n",
    "    graph.bind(\"sg\", SG)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Spotify Artist  and  hasNationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-28T13:51:21.658990623Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 387 ms, sys: 3.35 ms, total: 390 ms\n",
      "Wall time: 397 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the movies dataframe\n",
    "for index, row in wikidata_artists.iterrows():\n",
    "    row2 = spotify_artist_info.iloc[index]\n",
    "    \n",
    "    # create node\n",
    "    artist_uri = \"artist_\" + row['Url_spotify']\n",
    "    Artist = URIRef(SG[artist_uri])\n",
    "    g.add((Artist, RDF.type, SG.SpotifyArtist))\n",
    "    # data properties\n",
    "    g.add((Artist, SG['artistFollowersNum'], Literal(row2['Followers'], datatype=XSD.integer)))\n",
    "    g.add((Artist, SG['artistName'], Literal(row['Artist'], datatype=XSD.string)))\n",
    "    g.add((Artist, SG['artistPopularity'], Literal(row2['Popularity'], datatype=XSD.integer)))\n",
    "    if row['websiteLabel'] != '_':\n",
    "        g.add((Artist, SG['artistWebsite'], Literal(row['websiteLabel'], datatype=XSD.string)))\n",
    "    if row['start'] != '_':\n",
    "        g.add((Artist, SG['startWorkingPeriod'], Literal(row['start'], datatype=XSD.gYear)))\n",
    "    if row['end'] != '_':\n",
    "        g.add((Artist, SG['endWorkingPeriod'], Literal(row['end'], datatype=XSD.gYear)))\n",
    "    if row['dissolved'] != '_':\n",
    "        g.add((Artist, SG['dissolvedIn'], Literal(row['dissolved'], datatype=XSD.gYear)))\n",
    "    # obj prop - hasNationality\n",
    "    if row['country_codes'] != '_':\n",
    "        cc_list = row['country_codes'].split('+')\n",
    "        for cc in cc_list:\n",
    "            Country = URIRef(CNS[cc.lower()])\n",
    "            g.add((Artist, SG['hasNationality'], Country))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T15:37:38.503174900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 206 ms, sys: 1.9 ms, total: 208 ms\n",
      "Wall time: 207 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = write_and_empty_graph(g, 'spotify_artist.ttl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Spotify Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T17:59:14.615970900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.47 s, sys: 39.3 ms, total: 4.51 s\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset['Stream']=dataset['Stream'].fillna('_')\n",
    "for index, row in dataset.iterrows():\n",
    "    \n",
    "    # Create the node to add to the Graph\n",
    "    track_uri = \"track_\" + row['Uri'].split(':')[-1]\n",
    "    Track = URIRef(SG[track_uri])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Track, RDF.type, SG.SpotifyTrack))\n",
    "    g.add((Track, SG['trackName'], Literal(row['Track'], datatype=XSD.string)))\n",
    "    if not pd.isna(row['Duration_ms']):\n",
    "        g.add((Track, SG['trackAcousticness'], Literal(row['Acousticness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackDanceability'], Literal(row['Danceability'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackDuration'], Literal(row['Duration_ms'], datatype=XSD.integer)))\n",
    "        g.add((Track, SG['trackEnergy'], Literal(row['Energy'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackInstrumentalness'], Literal(row['Instrumentalness'], datatype=XSD.float)))    \n",
    "        g.add((Track, SG['trackKey'], Literal(row['Key'], datatype=XSD.integer)))\n",
    "        g.add((Track, SG['trackLiveness'], Literal(row['Liveness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackLoudness'], Literal(row['Loudness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackSpeechiness'], Literal(row['Speechiness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackTempo'], Literal(row['Tempo'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackValence'], Literal(row['Valence'], datatype=XSD.float)))\n",
    "    if row['Stream'] != '_':\n",
    "        g.add((Track, SG['trackStreams'], Literal(row['Stream'], datatype=XSD.integer)))\n",
    "    else:\n",
    "        g.add((Track, SG['trackStreams'], Literal(0, datatype=XSD.integer)))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T17:59:24.466282300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.5 ms, sys: 1.04 ms, total: 36.5 ms\n",
      "Wall time: 35.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "genres_set = set()\n",
    "spotify_artist_info['Genres'] = spotify_artist_info['Genres'].apply(lambda x: x.replace('[', '')\n",
    "                                                                            .replace(']', '')\n",
    "                                                                            .replace('\\'','')\n",
    "                                                                            .replace('\"',''))\n",
    "for index, row in spotify_artist_info.iterrows():\n",
    "    for genre in row['Genres'].split(', '):\n",
    "        # some songs have no associated genres and the replace series results in an empty string\n",
    "        if genre != '':\n",
    "            genres_set.add(genre.replace(' ', '_').replace('-', '_'))\n",
    "\n",
    "for genre in genres_set:\n",
    "    genre_uri = \"genre_\" + genre\n",
    "    Genre = URIRef(SG[genre_uri])\n",
    "    g.add((Genre, RDF.type, SG.Genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Spotify Album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T17:59:24.547281900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.14 s, sys: 15.9 ms, total: 1.15 s\n",
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add album type to CSV and remove duplicates in another var\n",
    "spotify_album['album_type'] = dataset['Album_type']\n",
    "spotify_album_2 = spotify_album.drop_duplicates().reset_index(drop=True)\n",
    "spotify_album_2['Album'] = spotify_album_2['Album'].fillna('_')\n",
    "\n",
    "for index, row in spotify_album_2.iterrows():\n",
    "    album_uri = 'album_' + row['Id'].split(':')[-1]\n",
    "    if row['Album'] != '_':\n",
    "        Album = URIRef(SG[album_uri])\n",
    "        g.add((Album, RDF.type, SG.SpotifyAlbum))\n",
    "        g.add((Album, SG['albumName'], Literal(row['Album'], datatype=XSD.string)))\n",
    "        g.add((Album, SG['albumReleaseDate'], Literal(row['Release_date'], datatype=XSD.date)))\n",
    "        g.add((Album, SG['albumTotalTracksNum'], Literal(row['Total_tracks'], datatype=XSD.integer)))\n",
    "        g.add((Album, SG['albumType'], Literal(row['album_type'], datatype=XSD.string))) # TODO check enum datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T17:59:27.901287600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.2 s, sys: 23.7 ms, total: 5.22 s\n",
      "Wall time: 5.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = write_and_empty_graph(g, 'nodes_spotify.ttl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### YouTube Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T17:03:12.347735Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 507 ms, sys: 9.03 ms, total: 516 ms\n",
      "Wall time: 519 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "youtube_api_channels['channelDescription'] = youtube_api_channels['channelDescription'].fillna('_')\n",
    "for index, row in youtube_api_channels.iterrows():\n",
    "    if row['channelId'] != '_':\n",
    "        channel_id = 'channel_' + row['channelId']\n",
    "        Channel = URIRef(SG[channel_id])\n",
    "        g.add((Channel, RDF.type, SG.YouTubeChannel))\n",
    "        g.add((Channel, SG['channelName'], Literal(row['originalChannel'], datatype=XSD.string)))\n",
    "        if row['channelDescription'] != '_':\n",
    "            g.add((Channel, SG['channelDescription'], Literal(row['channelDescription'], datatype=XSD.string)))\n",
    "        g.add((Channel, SG['channelViewCount'], Literal(row['viewCount'], datatype=XSD.integer)))\n",
    "        g.add((Channel, SG['channelSubscribersCount'], Literal(row['subscriberCount'], datatype=XSD.integer)))\n",
    "        g.add((Channel, SG['channelVideoCount'], Literal(row['videoCount'], datatype=XSD.integer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T17:03:24.778232900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 590 ms, sys: 7 ms, total: 597 ms\n",
      "Wall time: 603 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = write_and_empty_graph(g, 'nodes_yt_channels.ttl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T18:27:21.088369800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.4 s, sys: 23.7 ms, total: 3.42 s\n",
      "Wall time: 3.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset['Url_youtube'] = dataset['Url_youtube'].fillna('_')\n",
    "dataset['Description'] = dataset['Description'].fillna('_')\n",
    "dataset['Comments'] = dataset['Comments'].fillna(-1)\n",
    "dataset['Likes'] = dataset['Likes'].fillna(-1)\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    if row['Url_youtube'] != '_':\n",
    "        video_id = 'video_' + row['Url_youtube'].split('?v=')[-1]\n",
    "        Video = URIRef(SG[video_id])\n",
    "        g.add((Video, RDF.type, SG.YouTubeVideo))\n",
    "        g.add((Video, SG['videoTitle'], Literal(row['Title'], datatype=XSD.string)))\n",
    "        if row['Description'] != '_':\n",
    "            g.add((Video, SG['videoDescription'], Literal(row['Description'], datatype=XSD.string)))\n",
    "        if row['Comments'] != -1:\n",
    "            g.add((Video, SG['videoComments'], Literal(row['Comments'], datatype=XSD.integer)))\n",
    "        if row['Likes'] != -1:\n",
    "            g.add((Video, SG['videoLikes'], Literal(row['Likes'], datatype=XSD.integer)))\n",
    "        g.add((Video, SG['videoViews'], Literal(row['Views'], datatype=XSD.integer)))\n",
    "        g.add((Video, SG['isOfficialVideo'], Literal(row['official_video'], datatype=XSD.boolean)))\n",
    "        g.add((Video, SG['isLicensed'], Literal(row['Licensed'], datatype=XSD.boolean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-26T18:27:27.155438700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.3 s, sys: 31.2 ms, total: 2.33 s\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = write_and_empty_graph(g, 'nodes_yt_video.ttl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Object properties\n",
    "#### hasNationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T14:52:28.993753300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Already done in Spotify Artist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### containsTrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 444 ms, sys: 7.12 ms, total: 451 ms\n",
      "Wall time: 451 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# add album type to CSV and remove duplicates in another var\n",
    "dataset['Album_Id'] = spotify_album['Id']\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    album_uri = 'album_' + row['Album_Id'].split(':')[-1]\n",
    "    Album = URIRef(SG[album_uri])\n",
    "\n",
    "    track_uri = \"track_\" + row['Uri'].split(':')[-1]\n",
    "    Track = URIRef(SG[track_uri])\n",
    "        \n",
    "    g.add((Album, SG['containsTrack'], Track))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### isComposedBy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### isRelatedTo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 848 ms, sys: 8.48 ms, total: 857 ms\n",
      "Wall time: 856 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    if row['Url_youtube'] != '_' and row['Uri'] != '_':\n",
    "        video_id = 'video_' + row['Url_youtube'].split('?v=')[-1]\n",
    "        Video = URIRef(SG[video_id])\n",
    "\n",
    "        track_uri = \"track_\" + row['Uri'].split(':')[-1]\n",
    "        Track = URIRef(SG[track_uri])\n",
    "        \n",
    "        g.add((Video, SG['isRelatedTo'], Track))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### isPublishedBy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### isAvailableIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 214 ms, sys: 1.76 ms, total: 216 ms\n",
      "Wall time: 215 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add album type to CSV and remove duplicates in another var\n",
    "spotify_album_2 = spotify_album.drop_duplicates().reset_index(drop=True)\n",
    "spotify_album_2['Album'] = spotify_album_2['Album'].fillna('_')\n",
    "\n",
    "for index, row in spotify_album_2.iterrows():\n",
    "    album_uri = 'album_' + row['Id'].split(':')[-1]\n",
    "    if row['Album'] != '_':\n",
    "        Album = URIRef(SG[album_uri])\n",
    "        \n",
    "        if isinstance(row['Available_market'], list) and len(row['Available_market']) > 0:\n",
    "            for market in row['Available_market']:\n",
    "                if market != '_' and len(market) == 2:\n",
    "                    Country = URIRef(CNS[market.lower()])\n",
    "                    g.add((Album, SG['isAvailableIn'], Country))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### isOfficialChannel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### isWrittenBy  and  performsIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/IPython/core/magics/execution.py\", line 1325, in time\n",
      "    exec(code, glob, local_ns)\n",
      "  File \"<timed exec>\", line 5, in <module>\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/generic.py\", line 5902, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Series' object has no attribute 'split'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1030, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1122, in get_records\n",
      "    FrameInfo(\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 766, in __init__\n",
      "    ix = inspect.getsourcelines(frame)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py\", line 1244, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py\", line 1081, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset['Url_youtube'] = dataset['Url_youtube'].fillna('_')\n",
    "        \n",
    "for index, row in dataset.iterrows():\n",
    "\n",
    "    artist_uri = \"artist_\" + dataset['Url_spotify'].split('/')[-1]\n",
    "    Artist = URIRef(SG[artist_uri])\n",
    "    \n",
    "    track_uri = \"track_\" + row['Uri'].split(':')[-1]\n",
    "    Track = URIRef(SG[track_uri])\n",
    "    \n",
    "    #   isWrittenBy\n",
    "    g.add((Track, SG['isWrittenBy'], Artist))\n",
    "\n",
    "    #   performIn\n",
    "    if row['Url_youtube'] != '_':\n",
    "        video_id = 'video_' + row['Url_youtube'].split('?v=')[-1]\n",
    "        Video = URIRef(SG[video_id])\n",
    "        \n",
    "        g.add((Artist, SG['performsIn'], Video))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### hasGenre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:8\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "spotify_artist_info['Genres'] = spotify_artist_info['Genres'].apply(lambda x: x.replace('[', '')\n",
    "                                                                    .replace(']', '')\n",
    "                                                                    .replace('\\'','')\n",
    "                                                                    .replace('\"',''))\n",
    "\n",
    "for artist in wikidata_artists:\n",
    "    for row in spotify_artist_info.iterrows():\n",
    "        if artist['Artist'] == row['Artist']:\n",
    "            \n",
    "            artist_uri = \"artist_\" + artist['Url_spotify']\n",
    "            Artist = URIRef(SG[artist_uri])\n",
    "            \n",
    "            for genre in row['Genres'].split(', '):\n",
    "                if genre != '':\n",
    "                    genre_uri = \"genre_\" + genre.replace(' ', '_').replace('-', '_')\n",
    "                    Genre = URIRef(SG[genre_uri])\n",
    "                    \n",
    "                    g.add((Artist, SG['hasGenre'], Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# add album type to CSV and remove duplicates in another var\n",
    "spotify_album['Artist'] = dataset['Artist']\n",
    "spotify_album_2 = spotify_album.drop_duplicates().reset_index(drop=True)\n",
    "spotify_album_2['Album'] = spotify_album_2['Album'].fillna('_')\n",
    "\n",
    "for index, row in spotify_album_2.iterrows():\n",
    "    album_uri = 'album_' + row['Id'].split(':')[-1]\n",
    "    Album = URIRef(SG[album_uri])\n",
    "    \n",
    "    #TODO DOUBLE ALBUM ROWS (?)\n",
    "    \n",
    "    #search Artist in wikidata_artists:\n",
    "    for artist in wikidata_artists.iterrows():\n",
    "        if artist['Artist'] == row['Artist']:\n",
    "            artist_uri = \"artist_\" + artist['Url_spotify']\n",
    "            Artist = URIRef(SG[artist_uri])\n",
    "            g.add((Album, SG['isComposedBy'], Artist))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
