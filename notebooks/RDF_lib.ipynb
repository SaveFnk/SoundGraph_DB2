{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify and YouTube dataset population\n",
    "\n",
    "This notebook outlines the steps to create an RDF dataset based on the SoundGraph ontology, from the data import to RDF triple export in Turtle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv files path\n",
    "dataset_path='../data/Spotify_Youtube.csv'\n",
    "spotify_artist_path='../data/Artists.csv'\n",
    "spotify_artist_info_path='../data/Artist_info.csv'\n",
    "spotify_album_path='../data/Album_info.csv'\n",
    "wikidata_artists_path='../data/wikidata_artists.csv'\n",
    "wikidata_award_statements_path='../data/wikidata_award_statements.csv'\n",
    "wikidata_awards_path='../data/wikidata_awards.csv'\n",
    "youtube_api_channels_path='../data/youtubeapi_channels_complete.csv'\n",
    "#target folder where to save the output\n",
    "targetFolder='../rdf/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20718 entries, 0 to 20717\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        20718 non-null  int64  \n",
      " 1   Artist            20718 non-null  object \n",
      " 2   Url_spotify       20718 non-null  object \n",
      " 3   Track             20718 non-null  object \n",
      " 4   Album             20718 non-null  object \n",
      " 5   Album_type        20718 non-null  object \n",
      " 6   Uri               20718 non-null  object \n",
      " 7   Danceability      20716 non-null  float64\n",
      " 8   Energy            20716 non-null  float64\n",
      " 9   Key               20716 non-null  float64\n",
      " 10  Loudness          20716 non-null  float64\n",
      " 11  Speechiness       20716 non-null  float64\n",
      " 12  Acousticness      20716 non-null  float64\n",
      " 13  Instrumentalness  20716 non-null  float64\n",
      " 14  Liveness          20716 non-null  float64\n",
      " 15  Valence           20716 non-null  float64\n",
      " 16  Tempo             20716 non-null  float64\n",
      " 17  Duration_ms       20716 non-null  float64\n",
      " 18  Url_youtube       20248 non-null  object \n",
      " 19  Title             20248 non-null  object \n",
      " 20  Channel           20248 non-null  object \n",
      " 21  Views             20248 non-null  float64\n",
      " 22  Likes             20177 non-null  float64\n",
      " 23  Comments          20149 non-null  float64\n",
      " 24  Description       19842 non-null  object \n",
      " 25  Licensed          20248 non-null  object \n",
      " 26  official_video    20248 non-null  object \n",
      " 27  Stream            20142 non-null  float64\n",
      "dtypes: float64(15), int64(1), object(12)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# load the songs \n",
    "dataset = pd.read_csv(dataset_path, sep=',')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2079 entries, 0 to 2078\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  2079 non-null   int64 \n",
      " 1   Artist      2079 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 32.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the artists present\n",
    "spotify_artist = pd.read_csv(spotify_artist_path, sep=',')\n",
    "spotify_artist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2079 entries, 0 to 2078\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Artist      2079 non-null   object\n",
      " 1   Followers   2079 non-null   int64 \n",
      " 2   Genres      2079 non-null   object\n",
      " 3   Popularity  2079 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 65.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# load spotify artists information\n",
    "spotify_artist_info = pd.read_csv(spotify_artist_info_path, sep=',')\n",
    "spotify_artist_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20718 entries, 0 to 20717\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Id                20718 non-null  object\n",
      " 1   Album             20641 non-null  object\n",
      " 2   Total_tracks      20718 non-null  int64 \n",
      " 3   Release_date      20718 non-null  object\n",
      " 4   Available_market  20718 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 809.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# load spotify album information\n",
    "\n",
    "spotify_album = pd.read_csv(spotify_album_path, sep=',')\n",
    "spotify_album.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2079 entries, 0 to 2078\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Artist         2079 non-null   object\n",
      " 1   Url_spotify    2079 non-null   object\n",
      " 2   artistLabel    2079 non-null   object\n",
      " 3   websiteLabel   2079 non-null   object\n",
      " 4   start          2079 non-null   object\n",
      " 5   end            2079 non-null   object\n",
      " 6   dissolved      2079 non-null   object\n",
      " 7   country_codes  2079 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 130.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the wikidata artists information\n",
    "wikidata_artists=pd.read_csv(wikidata_artists_path,sep=',')\n",
    "wikidata_artists.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1035 entries, 0 to 1034\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   artist_spotify_id  1035 non-null   object\n",
      " 1   award_id           1035 non-null   int64 \n",
      " 2   award_year         1035 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 24.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the wikidata award statements information\n",
    "wikidata_award_statements=pd.read_csv(wikidata_award_statements_path,sep=',')\n",
    "wikidata_award_statements.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205 entries, 0 to 204\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   award_id    205 non-null    int64 \n",
      " 1   award_name  205 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the wikidata awards information\n",
    "wikidata_awards=pd.read_csv(wikidata_awards_path,sep=',')\n",
    "wikidata_awards.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6715 entries, 0 to 6714\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   channelId           6715 non-null   object\n",
      " 1   title               6715 non-null   object\n",
      " 2   channelDescription  4241 non-null   object\n",
      " 3   viewCount           6715 non-null   object\n",
      " 4   subscriberCount     6715 non-null   object\n",
      " 5   videoCount          6715 non-null   object\n",
      " 6   error               6715 non-null   int64 \n",
      " 7   originalChannel     3358 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 419.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# load the youtube channels information\n",
    "youtube_api_channels=pd.read_csv(youtube_api_channels_path,sep=',')\n",
    "youtube_api_channels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDFLib import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use RDFLib, the following installation is required:\n",
    "\n",
    "<code>pip3 install rdflib</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# rdflib knows about some namespaces, like FOAF\n",
    "from rdflib.namespace import FOAF, XSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the countries and the SoundGraph ontology namespaces not known by RDFlib\n",
    "CNS = Namespace(\"https://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "SG = Namespace(\"https://www.dei.unipd.it/db2/ontology/soundgraph\")\n",
    "\n",
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"sg\", SG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spotify Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 462 ms, sys: 31.2 ms, total: 494 ms\n",
      "Wall time: 493 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the movies dataframe\n",
    "for index, row in wikidata_artists.iterrows():\n",
    "    row2= spotify_artist_info.iloc[index]\n",
    "    \n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the movie id as URI\n",
    "    artist_uri=\"artist_\"+row['Url_spotify']\n",
    "    Artist= URIRef(SG[artist_uri])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Artist, RDF.type, SG.SpotifyArtist))\n",
    "    g.add((Artist, SG['artistFollowersNum'], Literal(row2['Followers'], datatype=XSD.integer)))\n",
    "    g.add((Artist, SG['artistName'],Literal(row['Artist'], datatype=XSD.string)))\n",
    "    g.add((Artist, SG['artistPopularity'],Literal(row2['Popularity'], datatype=XSD.integer)))\n",
    "    if row['websiteLabel'] != '_':\n",
    "        g.add((Artist, SG['artistWebsite'],Literal(row['websiteLabel'], datatype=XSD.string)))\n",
    "    if row['start'] != '_':\n",
    "        g.add((Artist, SG['startWorkingPeriod'],Literal(row['start'], datatype=XSD.gYear)))\n",
    "    if row['end'] != '_':\n",
    "        g.add((Artist, SG['endWorkingPeriod'],Literal(row['end'], datatype=XSD.gYear)))\n",
    "    if row['dissolved'] != '_':\n",
    "        g.add((Artist, SG['dissolvedIn'],Literal(row['dissolved'], datatype=XSD.gYear)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20718 entries, 0 to 20717\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        20718 non-null  int64  \n",
      " 1   Artist            20718 non-null  object \n",
      " 2   Url_spotify       20718 non-null  object \n",
      " 3   Track             20718 non-null  object \n",
      " 4   Album             20718 non-null  object \n",
      " 5   Album_type        20718 non-null  object \n",
      " 6   Uri               20718 non-null  object \n",
      " 7   Danceability      20716 non-null  float64\n",
      " 8   Energy            20716 non-null  float64\n",
      " 9   Key               20716 non-null  float64\n",
      " 10  Loudness          20716 non-null  float64\n",
      " 11  Speechiness       20716 non-null  float64\n",
      " 12  Acousticness      20716 non-null  float64\n",
      " 13  Instrumentalness  20716 non-null  float64\n",
      " 14  Liveness          20716 non-null  float64\n",
      " 15  Valence           20716 non-null  float64\n",
      " 16  Tempo             20716 non-null  float64\n",
      " 17  Duration_ms       20716 non-null  float64\n",
      " 18  Url_youtube       20248 non-null  object \n",
      " 19  Title             20248 non-null  object \n",
      " 20  Channel           20248 non-null  object \n",
      " 21  Views             20248 non-null  float64\n",
      " 22  Likes             20177 non-null  float64\n",
      " 23  Comments          20149 non-null  float64\n",
      " 24  Description       19842 non-null  object \n",
      " 25  Licensed          20248 non-null  object \n",
      " 26  official_video    20248 non-null  object \n",
      " 27  Stream            20142 non-null  float64\n",
      "dtypes: float64(15), int64(1), object(12)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spotify Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.73 s, sys: 112 ms, total: 7.84 s\n",
      "Wall time: 7.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, row in dataset.iterrows():\n",
    "    \n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the movie id as URI\n",
    "    track_uri=\"track_\"+row['Uri']\n",
    "    Track= URIRef(SG[track_uri])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Track, RDF.type, SG.SpotifyArtist))\n",
    "    g.add((Track, SG['trackName'], Literal(row['Track'], datatype=XSD.string)))\n",
    "    if row['Duration_ms']:\n",
    "        g.add((Track, SG['trackAcousticness'],Literal(row['Acousticness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackDanceability'],Literal(row['Danceability'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackDuration'],Literal(row['Duration_ms'], datatype=XSD.positiveInteger)))\n",
    "        g.add((Track, SG['trackEnergy'],Literal(row['Energy'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackInstrumentalness'],Literal(row['Instrumentalness'], datatype=XSD.float)))    \n",
    "        g.add((Track, SG['trackKey'],Literal(row['Key'], datatype=XSD.integer)))\n",
    "        g.add((Track, SG['trackLiveness'],Literal(row['Liveness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackLoudness'],Literal(row['Loudness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackSpeechiness'],Literal(row['Speechiness'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackTempo'],Literal(row['Tempo'], datatype=XSD.float)))\n",
    "        g.add((Track, SG['trackValence'],Literal(row['Valence'], datatype=XSD.float)))\n",
    "    if row['Stream'] != '_':\n",
    "        g.add((Track, SG['trackStreams'],Literal(row['Stream'], datatype=XSD.long)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84.4 ms, sys: 9.34 ms, total: 93.7 ms\n",
      "Wall time: 92.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "genres_set = set()\n",
    "spotify_artist_info['Genres']=spotify_artist_info['Genres'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\\'','').replace('\"',''))\n",
    "for index, row in spotify_artist_info.iterrows():\n",
    "    for genre in row['Genres'].split(', '):\n",
    "        genres_set.add(genre.replace(' ', '_').replace('-', '_'))\n",
    "\n",
    "for genre in genres_set:\n",
    "    genre_uri= \"genre_\" + genre\n",
    "    Genre= URIRef(SG[genre_uri])\n",
    "    g.add((Genre, RDF.type, SG.Genre))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spotify Album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.16 s, sys: 80.6 ms, total: 2.24 s\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spotify_album['album_type'] = dataset['Album_type']\n",
    "spotify_album_2 = spotify_album.drop_duplicates().reset_index(drop=True)\n",
    "spotify_album_2['Album'] = spotify_album_2['Album'].fillna('_')\n",
    "for index, row in spotify_album_2.iterrows():\n",
    "    album_id = 'album_' + row['Id']\n",
    "\n",
    "    if row['Album'] != '_':\n",
    "        Album = URIRef(SG[album_id])\n",
    "        g.add((Album, RDF.type, SG.SpotifyAlbum))\n",
    "        g.add((Album, SG['albumName'], Literal(row['Album'], datatype=XSD.string)))\n",
    "        g.add((Album, SG['albumReleaseDate'], Literal(row['Release_date'], datatype=XSD.date)))\n",
    "        g.add((Album, SG['albumTotalTracksNum'], Literal(row['Total_tracks'], datatype=XSD.integer)))\n",
    "        g.add((Album, SG['albumType'], Literal(row['album_type'], datatype=XSD.string))) # TODO check enum datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.47 s, sys: 21.3 ms, total: 9.49 s\n",
      "Wall time: 9.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(targetFolder + 'nodes_spotify.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"sg\", SG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YouTube Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.06 s, sys: 30 ms, total: 1.09 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO id == _ => skipped\n",
    "for index, row in youtube_api_channels.iterrows():\n",
    "    if row['channelId'] != '_':\n",
    "        channel_id = 'channel_' + row['channelId']\n",
    "        Channel = URIRef(SG[channel_id])\n",
    "        g.add((Channel, RDF.type, SG.YouTubeChannel))\n",
    "        g.add((Channel, SG['channelName'], Literal(row['originalChannel'], datatype=XSD.string)))\n",
    "        g.add((Channel, SG['channelDescription'], Literal(row['channelDescription'], datatype=XSD.string)))\n",
    "        g.add((Channel, SG['channelViewCount'], Literal(row['viewCount'], datatype=XSD.long)))\n",
    "        g.add((Channel, SG['channelSubscribersCount'], Literal(row['subscriberCount'], datatype=XSD.integer)))\n",
    "        g.add((Channel, SG['channelVideoCount'], Literal(row['videoCount'], datatype=XSD.integer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 847 ms, sys: 18.2 ms, total: 865 ms\n",
      "Wall time: 870 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(targetFolder + 'nodes_yt_channels.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"sg\", SG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.7 s, sys: 90.4 ms, total: 5.79 s\n",
      "Wall time: 5.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset['Url_youtube'] = dataset['Url_youtube'].fillna('_')\n",
    "for index, row in dataset.iterrows():\n",
    "    if row['Url_youtube'] != '_':\n",
    "        if type(row['Url_youtube']) != type('a'): print(row['Url_youtube'], type(row['Url_youtube']))\n",
    "        video_id = 'video_' + row['Url_youtube'].split('?v=')[-1]\n",
    "        Video = URIRef(SG[video_id])\n",
    "        g.add((Video, RDF.type, SG.YouTubeVideo))\n",
    "        g.add((Video, SG['videoTitle'], Literal(row['Title'], datatype=XSD.string)))\n",
    "        g.add((Video, SG['videoDescription'], Literal(row['Description'], datatype=XSD.string)))\n",
    "        g.add((Video, SG['videoComments'], Literal(row['Comments'], datatype=XSD.integer)))\n",
    "        g.add((Video, SG['videoLikes'], Literal(row['Likes'], datatype=XSD.integer)))\n",
    "        g.add((Video, SG['videoViews'], Literal(row['Views'], datatype=XSD.long)))\n",
    "        g.add((Video, SG['isOfficialVideo'], Literal(row['official_video'], datatype=XSD.boolean)))\n",
    "        g.add((Video, SG['isLicensed'], Literal(row['Licensed'], datatype=XSD.boolean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.43 s, sys: 9.98 ms, total: 3.44 s\n",
      "Wall time: 3.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(targetFolder + 'nodes_yt_video.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db2",
   "language": "python",
   "name": "db2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
